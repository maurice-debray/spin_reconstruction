{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b780b7af-aee0-4d92-b830-64e9b9d3c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit, vectorize, float64, types, int64, prange\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.sparse import dia_matrix\n",
    "from datetime import datetime\n",
    "from qutip import sigmax, sigmay, sigmaz, jmat\n",
    "import time\n",
    "import h5py\n",
    "from labellines import labelLine, labelLines\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac206793-8fe0-4834-ad5d-2cd608cb7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b903a99-d470-48a6-b015-d17b6d435997",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_par_weight = 0#(8e1)**(-2)\n",
    "nb_par_weight = gamma_ratio**2\n",
    "tolerance = 2\n",
    "nb_tolerance = tolerance/gamma_ratio\n",
    "cutoff = 1000\n",
    "revert_a_par = True\n",
    "\n",
    "file = f\"reconstructed_quarter_{tolerance}_nb_{cutoff}_factor2.hdf5\"\n",
    "couplings_file = \"couplings_quarter.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792b5a5-4378-4466-b991-b7c00b389712",
   "metadata": {},
   "source": [
    "# State reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daaa4792-069c-44fd-bdbd-90af6f51858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def index_to_coord(index, max_distance, site_nb):\n",
    "    center = max_distance // 2\n",
    "    return (\n",
    "            index // (max_distance**2 * site_nb) - center,\n",
    "            index // (max_distance * site_nb) % max_distance - center,\n",
    "            index // site_nb % max_distance - center,\n",
    "            index % site_nb\n",
    "        )\n",
    "\n",
    "@jit\n",
    "def coord_to_index(vec, max_distance, site_nb):\n",
    "    center = max_distance // 2\n",
    "    return (\n",
    "                            (\n",
    "                                (\n",
    "                                    (vec[0] + center)*max_distance + (vec[1] + center)\n",
    "                                )*max_distance\n",
    "                                + (vec[2] + center)\n",
    "                            )*site_nb\n",
    "                            + vec[3]\n",
    "                       \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a78bf20-e87b-4aeb-99f0-2bccc9dc4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def exchange_columns(couplings, permutation, a, b):\n",
    "    a, b = min(a, b), max(a, b)\n",
    "    permutation[a], permutation[b] = permutation[b], permutation[a]\n",
    "    for i in range(a):\n",
    "        couplings[i, a], couplings[i, b] = couplings[i, b], couplings[i, a]\n",
    "    for i in range(a+1, b):\n",
    "        couplings[a, i], couplings[i, b] = couplings[i, b], couplings[a, i]\n",
    "    for i in range(b+1, couplings.shape[0]): \n",
    "        couplings[a, i], couplings[b, i] = couplings[b, i], couplings[a, i]\n",
    "\n",
    "def set_placing_order(couplings):\n",
    "    \"\"\"\n",
    "    First spin will always be niobium. Then we sort all other spins\n",
    "    \"\"\"\n",
    "    n_tot = couplings.shape[0]\n",
    "    permutation = np.arange(n_tot)\n",
    "    for i in range(1, n_tot):\n",
    "        next_index = np.nanargmax(np.abs(couplings[:i,i:]))%(n_tot-i) + i\n",
    "        if next_index != i:\n",
    "            exchange_columns(couplings, permutation, i, next_index)\n",
    "    return couplings, permutation\n",
    "\n",
    "@jit(parallel=True)\n",
    "def compute_new_possible_config(possible_configurations, len_all_couplings, len_config, n_placed):\n",
    "    new_possible_configurations = np.zeros((len(possible_configurations)*len_all_couplings, len_config), dtype = np.uint64)\n",
    "    for c in prange(len(possible_configurations)):\n",
    "        config = possible_configurations[c]\n",
    "        # Get candidates\n",
    "        for site in prange(len_all_couplings):\n",
    "            for i in prange(n_placed+1):\n",
    "                new_possible_configurations[c*len_all_couplings + site, i] = config[i]\n",
    "            new_possible_configurations[c*len_all_couplings + site, n_placed] = site\n",
    "    return new_possible_configurations\n",
    "\n",
    "@jit(parallel=True)\n",
    "def all_error_cost(configs, coupl, a_par_data, nb_par_data, n_max, all_couplings, a_par, nb_par, a_par_weight, nb_par_weight, tolerance, nb_tolerance):\n",
    "    errors = np.zeros(len(configs))\n",
    "    n = coupl.shape[0]\n",
    "    for k in prange(len(configs)):\n",
    "        err = 0.0\n",
    "        config = configs[k]\n",
    "        for i in range(n_max):\n",
    "            if not np.isnan(a_par_data[i]):\n",
    "                err += a_par_weight * (a_par[config[i]] - a_par_data[i])**2\n",
    "            if np.isnan(nb_par[config[i]]) or np.abs(nb_par[config[i]] - nb_par_data[i]) > nb_tolerance:\n",
    "                err = np.inf\n",
    "                break\n",
    "            if not np.isnan(nb_par_data[i]):\n",
    "                err += nb_par_weight * (nb_par[config[i]] - nb_par_data[i])**2\n",
    "            for j in range(i+1, n_max):\n",
    "                if np.isnan(all_couplings[config[i], config[j]]) or np.abs(all_couplings[config[i], config[j]] - coupl[i,j]) > tolerance:\n",
    "                    err = np.inf\n",
    "                    break\n",
    "                if not np.isnan(coupl[i, j]):\n",
    "                    err += (coupl[i, j] - all_couplings[config[i], config[j]])**2\n",
    "            if err == np.inf:\n",
    "                break\n",
    "        errors[k] = err\n",
    "    return errors\n",
    "\n",
    "def compute_sites(couplings, a_par_data, nb_par_data, site_nb, all_couplings, tolerance, nb_tolerance, a_par, nb_par, a_par_weight, nb_par_weight, cutoff, verbose = True):\n",
    "    n_placed = 1\n",
    "    max_distance = round((all_couplings.shape[0]//site_nb)**(1/3))\n",
    "    if max_distance**3 * site_nb != all_couplings.shape[0]:\n",
    "        raise ValueError(\"Impossible to get the right max_distance\")\n",
    "    n_tot = couplings.shape[0]\n",
    "    couplings, permutation = set_placing_order(couplings.copy())\n",
    "    a_par_data = a_par_data[permutation]\n",
    "    possible_configurations = np.array( [[i] + [0]*(n_tot-1) for i in range(max_distance**3*site_nb)], dtype = np.uint64)\n",
    "    inf_index = max_distance**3*site_nb\n",
    "    errors = np.zeros(max_distance**3*site_nb)\n",
    "    argsort_error = np.arange(max_distance**3*site_nb)\n",
    "    while n_placed < n_tot:\n",
    "        # Be careful, position relative to edge_spin\n",
    "        edge_spin = np.nanargmax(couplings[:n_placed,n_placed])\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Placing {n_placed} (linked to {edge_spin}). {len(possible_configurations)}*{len(all_couplings)} cases to process.\")\n",
    "        new_possible_configurations = compute_new_possible_config(possible_configurations, len(all_couplings), n_tot, n_placed)\n",
    "        checkpoint = possible_configurations, permutation, errors[argsort_error[:min(cutoff, inf_index)]], True\n",
    "        errors = all_error_cost(new_possible_configurations, couplings, a_par_data, nb_par_data, n_placed + 1, all_couplings, a_par, nb_par, a_par_weight, nb_par_weight, tolerance, nb_tolerance)\n",
    "        argsort_error = np.argsort(errors)\n",
    "        inf_index = np.searchsorted(errors, np.inf, sorter=argsort_error)\n",
    "        if inf_index == 0:\n",
    "            if verbose:\n",
    "                print(\"Ending prematurely\")\n",
    "            return checkpoint\n",
    "        del checkpoint\n",
    "        possible_configurations = new_possible_configurations[argsort_error[:min(cutoff, inf_index)]].copy()\n",
    "        n_placed+=1\n",
    "    return possible_configurations, permutation, errors[argsort_error[:min(cutoff, inf_index)]], False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d41788-d74c-41f1-8ff2-66f9b043c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_configuration(sites, original):\n",
    "    \"\"\"\n",
    "    Check if configurations are the same up to a translation\n",
    "    \"\"\"\n",
    "    x_sites = np.min(sites[:,0])\n",
    "    x_original = np.min(original[:,0])\n",
    "    y_sites = np.min(sites[:,1])\n",
    "    y_original = np.min(original[:,1])\n",
    "    z_sites = np.min(sites[:,2])\n",
    "    z_original = np.min(original[:,2])\n",
    "\n",
    "    # useless allocation here we could do it in place...\n",
    "    sites = sites + np.array([[x_original - x_sites, y_original - y_sites, z_original - z_sites, 0]])\n",
    "    sites = np.sort(sites, axis=0)\n",
    "    original = np.sort(original, axis=0)\n",
    "    return np.array_equal(sites, original)\n",
    "\n",
    "    \n",
    "# https://stackoverflow.com/questions/11649577/how-to-invert-a-permutation-array-in-numpy\n",
    "def invert_permutation(p):\n",
    "    \"\"\"Return an array s with which np.array_equal(arr[p][s], arr) is True.\n",
    "    The array_like argument p must be some permutation of 0, 1, ..., len(p)-1.\n",
    "    \"\"\"\n",
    "    p = np.asanyarray(p) # in case p is a tuple, etc.\n",
    "    s = np.empty_like(p)\n",
    "    s[p] = np.arange(p.size)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c7df0-8e86-4265-8ce2-686200c1a03d",
   "metadata": {},
   "source": [
    "###  Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c915d57-342d-41a8-bd98-120011365eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from measurement_data import data_header, renormalized_data, nb_par_data\n",
    "from measurement_data import a_par_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2c715-fc96-4b36-b209-f288f8ab1d2e",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5feb1a5-f920-4c6f-951b-8f115f32ed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65f76c1f3a14afc85dff54c05f00c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.isfile(file):\n",
    "    pass\n",
    "    # raise ValueError(f\"A file named {file} already exists\")\n",
    "\n",
    "n_partial = 0\n",
    "\n",
    "with h5py.File(couplings_file, \"r\") as f:\n",
    "    with h5py.File(file, \"w\") as g:\n",
    "        mdata = g.create_group(\"measured_data\")\n",
    "        mdata.create_dataset(name=\"WW_couplings\", data=renormalized_data)\n",
    "        mdata.create_dataset(name=\"A_par_couplings\", data=a_par_data)\n",
    "        for k, v in tqdm(f['couplings'].items()):\n",
    "            all_couplings = v[\"SEDOR_couplings\"][:]\n",
    "            a_parallel = v[\"A_par_couplings\"][:]\n",
    "            nb_par = v[\"NB_couplings\"][:]\n",
    "            final_sites, permutation, errors, ended_prematurely = compute_sites(\n",
    "                renormalized_data,\n",
    "                a_par_data,\n",
    "                nb_par_data,\n",
    "                site_nb = site_nb,\n",
    "                all_couplings = all_couplings,\n",
    "                tolerance = tolerance,\n",
    "                nb_tolerance = nb_tolerance,\n",
    "                a_par = a_parallel,\n",
    "                nb_par = nb_par,\n",
    "                a_par_weight = a_par_weight,\n",
    "                nb_par_weight = nb_par_weight,\n",
    "                cutoff=cutoff,\n",
    "                verbose=False,\n",
    "            )\n",
    "            if ended_prematurely:\n",
    "                n_partial += 1\n",
    "            if len(final_sites) == 0:\n",
    "                print(k, v)\n",
    "                print(final_sites, permutation, errors, ended_prematurely)\n",
    "            gr = g.create_group(f\"Reconstructed_from_{k}\")\n",
    "            gr.attrs[\"ended_prematurely\"] = ended_prematurely\n",
    "            gr.attrs[\"cutoff\"] = cutoff\n",
    "            gr.attrs[\"tolerance\"] = tolerance\n",
    "            gr.attrs[\"nb_tolerance\"] = nb_tolerance\n",
    "            gr.attrs[\"a_par_weight\"] = a_par_weight\n",
    "            gr.attrs[\"revert_a_par\"] = revert_a_par\n",
    "            gr.attrs[\"nb_par_weight\"] = nb_par_weight\n",
    "            for k, val in v.attrs.items():\n",
    "                gr.attrs[k] = val\n",
    "\n",
    "            gr.create_dataset(name=\"sites\", data = final_sites, dtype=np.int64)\n",
    "            gr.create_dataset(name=\"permutation\", data = permutation, dtype=np.uint64)\n",
    "            gr.create_dataset(name=\"errors\", data = errors)\n",
    "        g.attrs[\"n_partial_solutions\"] = n_partial\n",
    "        g.attrs[\"revert_a_par\"] = revert_a_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f9fd18-6e55-411d-9acd-362eff435c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(n_partial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
